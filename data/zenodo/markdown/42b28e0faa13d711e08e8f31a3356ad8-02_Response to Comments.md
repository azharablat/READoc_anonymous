Evaluation report (triage round 1) for TEBT-2024-0010

# Submission Information Table

| Submission Title | **Protocol for a Systematic Review of Industrial Animal Operations and Community Health** |
| --- | --- |
| Submission Reference | TEBT-2024-0010 |
| Handling Editor | Paul Whaley | ORCID 0000-0003-4021-0785 |
| Number of Reviewers | 1 (handling editor for triage) |
| Submission Type | Study Protocol |
| Preprint DOI | <https://zenodo.org/doi/10.5281/zenodo.11110844> |
| Status | In Editorial Review |
| Evaluation Date | 14 Jun 2024 |
| Evaluation Round | Triage round 1 |
| Recommendation | Revise |
| Handling Editor’s Explanation for Recommendation | Revision is being recommended to avoid unnecessary rounds to the peer-review process and provide additional information that reviewers will need in order to provide comprehensive and informed comments about the planned methods for this research. |

# Summary of article and editor recommendations

This is a potentially very interesting and important review of the health effects of general population exposure to industrial food production. The first major issue with the current version of the planned methods is a need for more clarity as to whether the authors’ intent is to conduct a large exploratory analysis of all existing relevant data, or a focused analysis of specific hypotheses in relation to how industrial food production can affect health. This matters for the feasibility of the planned work and the selection of appropriate methods for conducting it. The second issue is that more information needs to be provided about some of the specifics of the planned methods, to allow the reviewers to make fully-informed judgements - in particular about the appropriateness of the analysis plan (the synthesis methods) in relation to the research objectives.

**We thank the editor for their time and comments on our protocol. To address the question about the paper’s intent, we have revised our objectives section by stating the hypotheses that we plan to evaluate in our systematic review:**

**“We plan to test the following three hypotheses in our systematic review:**

1. **People with community-based exposures to industrial animal operations are more likely to experience adverse respiratory health outcomes compared to individuals living further from industrial animal operations.**
2. **People with community-based exposures to industrial animal operations are more likely to experience adverse gastrointestinal outcomes compared to individuals living further from industrial animal operations.**
3. **People with community-based exposures to industrial animal operations are more likely to be colonized or infected with pathogens (e.g., *E. coli*, *Salmonella)* compared to individuals living further from industrial animal operations.” (Line 113-122)**

**We have clarified our analysis plan and have stated that we do not expect a meta-analysis to be possible given the heterogeneity of our expected data:**

**“We plan to use a coding process to analyze our data after extraction. We have created a sample codebook (Section 4.6.4) based on our training dataset. Once all data has been extracted, we will begin coding the data using an iterative process. During this process, new codes will be created as necessary and previously coded data will be revisited as the codebook evolves.**

**Based on previous reviews (O’Connor et al., 2010, 2017; Son et al., 2024), we anticipate heterogeneity in study design (with regard to methods for exposure and outcome assessment and statistical methods) across identified studies, which may limit our ability to conduct meta-analysis. We plan to combine compatible studies when possible, however, to generate summary estimates that could provide insight into quantitative relationships between community exposure to animal operations and adverse human health outcomes. We will not exclude studies based on their compatibility with other studies for meta-analysis.**

**We will synthesize data into summary measures when individual studies are sufficiently similar, allowing for meaningful comparisons and synthesis of findings. Quantitative synthesis will be contingent upon whether study designs are compatible (e.g., all cross-sectional design), exposures and outcome measures are comparable, outcome measures are reported on similar scales or can be converted to the same scale, and the included studies are methodologically sound. Potential summary statistics may include prevalence Odds Ratios (OR), regression coefficients (*β*s, or mean differences), or prevalence ratios. Heterogeneity will be explored using I2 statistic, a measure that quantifies the degree of variability among effect sizes from individual studies. It represents the proportion of total variation across studies that is due to heterogeneity rather than chance. The I2 statistic is interpreted as indicating low heterogeneity (0-40%), moderate heterogeneity (30-60%), substantial heterogeneity (50-90%), or considerable heterogeneity (75-100%) (Higgins et al., 2023). Although an assessment of the I2 can be informative, it is also important to contextualize this metric with other factors such as study quality, sample size, and methodological diversity across studies when interpreting the meta-analysis results.**

**We may also perform sensitivity analyses by examining the effects of excluding studies with heterogeneous results as well as performing subgroup analyses by excluding individual or subsets of studies with characteristics that might be influential. For example, we may conduct a sub-analysis on school-based exposure studies as compared to residence-based exposure studies. If enough studies are available, a more formal approach to perform a subgroup analysis, clustering studies by specific characteristics to determine the impact on statistical heterogeneity, will be conducted.**

**For studies that are not amenable to quantitative synthesis, we will use the Synthesis without Meta-analysis (SwiM) reporting guideline, which was developed for use in systematic reviews in which meta-analyses of effect estimates may not be possible or appropriate for at least some outcomes (Campbell et al., 2020). Although this guideline was developed for the presentation of intervention studies rather than observational studies, many of the reporting items outlined are still applicable to observational study presentation, including the need to explain criteria used to prioritize results for summary and synthesis, explain and provide a rationale for groups used in synthesis, describe methods used to assess certainty of the synthesis findings, describe data presentation methods, and to report on the limitations of the synthesis (Campbell et al., 2020).” (Lines 247-293)**

# Checklist of minimum required information

Y = Yes | N = No | X = Not Applicable

| **Present** | **Item checked** |
| --- | --- |
| Y | Preprint, relevant revision materials, and supplemental material available on Zenodo |
| Y | Full name, affiliations, and ORCIDs (if available) of each author are present |
| Y | Structured abstract has been provided |
| Y | Author contributions in the form of a CRediT statement have been given |
| Y | Complete funding details are given, or “no funding” is declared |
| N | An informative disclosure of interests for all authors has been provided, or disclosure declined  **Each author has completed the EBT template for declaration of financial and non-financial interests and these forms have been compiled into a singular PDF and resubmitted with the revised manuscript. Please see the document titled 04 – Declaration of Interests\_v2.pdf.** |
| X | 3rd-party data and program code are fully cited, if relevant (TOP 1, level 3) |
| N | Data and code availability has been stated and links to both are functional  **We currently do not have data or code to submit with our protocol. In Section 4.6.3., we have submitted an Open Science Framework link to our sample codebook.** |
| N | One or more appropriate reporting checklists for submission type have been completed  **We apologize for this oversight and have included a completed PRISMA-P checklist in our materials. Please see the document titled 05 – Prisma P Delcaration.pdf.** |
| Y | Supplemental materials have plain English file names |

## Comments about minimum required information

1. The authors should check there is no grant number or other reference that should be included as part of the funding details.

**Our source of funding, the Silicon Valley Community Foundation, does not provide grant numbers.**

1. It is not compulsory but at EBT we do encourage authors to complete a structured declaration of financial and non-financial interests. Note this is not a declaration of *conflicts* of interest, but an assessment of interests that may need to be managed in order to prevent such conflicts. The template we offer (recommended but not required) is here, with an example of a completed declaration here.

**Each author has completed the EBT template for declaration of financial and non-financial interests and these forms have been compiled into a singular PDF and resubmitted with the revised manuscript. Please see the document titled 04 – Declaration of Interests\_v2.pdf.**

1. A PRISMA-P checklist has been provided but not completed.

**We have now included a completed PRISMA-P checklist in our materials. Please see the document titled 05 – Prisma P Delcaration.pdf.**

1. Minor issue, but preferred titling for protocols at EBT is to state the topic of the research, followed by a colon, followed by “a protocol for [insert study design]”

**The title has been updated to “Health Impacts Associated with Residential Exposure to Animal Feeding Operations: A Protocol for A Systematic Review”.**

1. I appreciate the authors do not yet have any data, but the cover letter asks for ethical issues around availability to be anticipated (if there are none, then it is fine to say so), and for the repository where the data will be placed to also be provided.

**We now state that we do not anticipate any ethical issues with regards to data availability. We plan to store our data on Open Science Framework and have updated our manuscript to reflect this:**

**“We do not anticipate any ethical issues with regards to data availability.” (Lines 202-203)**

**“Our final dataset will be published on Open Science Framework.” (Lines 170-171).**

# Structured evaluation

***KEY: R = Revisions recommended. N = No issues identified at this time. X = Not applicable.***

| **Domain** | D1. Clarity of objective and appropriateness of systematic review methodology |
| --- | --- |
| **Compliance** | Important issues identified that should be addressed prior to peer-review |
| **Specific Issues** | N Context and contribution, including motivation and position in field  R Research mode appropriately confirmatory rather than exploratory  R Target questions or knowledge goals (e.g. PECO) clear and suitably focused  R Feasibility of the planned work  X Other issues (indicated below) |
| **Comments** | 1. In current form, this protocol looks more like a plan for a large, exploratory study of the complete primary literature investigating the health effects of exposure to animal operations, rather than a systematic review aimed at answering a specific research question. (Indeed, at line 215 it is stated: “Given the aim of summarizing as much available evidence on the topic as possible”, which further suggests this may be a mapping exercise). Either goal is fine, but if it is the former I would recommend recasting the plan as for a systematic evidence map with descriptive analysis, and if the latter then focusing on a small number of hypotheses to test via analysis of existing literature.  **We agree that our language in Line 215 was unclear and have removed this language. Further, we have updated our objectives to reflect the 3 hypotheses we plan to evaluate in our review:**  **“Our objective is to conduct a systematic review of adverse health outcomes associated with community exposure to intensive animal operations. Our population of interest is individuals with community-based exposures to industrial animal operations, where an “animal operation” is defined as any operation that produces land animals for food, irrespective of size or methods of production. Exposure to these operations may be estimated using any relevant metric including physical distance to an operation, animal density, or levels of an indicator contaminant (e.g., endotoxins). We aim to study all relevant health outcomes, which includes a wide range of physician-diagnosed or self-reported outcomes, ranging from quality-of-life measures to sub-clinical measures of disease (e.g., biomarkers).” (Lines 101-111)**  **“We plan to test the following three hypotheses in our systematic review:**   1. **People with community-based exposures to animal feeding operations are more likely to experience adverse respiratory health outcomes compared to people living further from animal feeding operations.** 2. **People with community-based exposures to animal feeding operations are more likely to experience adverse gastrointestinal outcomes compared to people living further from animal feeding operations.** 3. **People with community-based exposures to animal feeding operations are more likely to be colonized or infected with pathogens (e.g., *E. coli*, *Salmonella)* compared to people living further from animal feeding operations.” (Lines 113-122)**   2. A clearer definition of “animal operations” is needed. Currently it is described illustratively rather than defined precisely, even including arable farming where manure is applied to land. This seems surprising to me.  **We have chosen to utilize the term “animal feeding operations” to better describe the types of facilities we are interested in. We have defined “animal feeding operation” in our dictionary (Section 4.1) as follows:**  **“Animal feeding operation will be defined as any operation that produces land animals for food, irrespective of size or methods of production. Our use of the term should not be confused with the regulatory designation “AFO” as defined by the US Environmental Protection Agency.” (Lines 402-404)**  3. The objectives of the study, if this is a systematic review rather than evidence map, should be framed as precise PECO statements - not just the eligibility criteria.  **We have revised our objectives and reframed them using PECO:**  **“Our objective is to conduct a systematic review of adverse health outcomes associated with community exposure to intensive animal operations. Our population of interest is individuals with community-based exposures to industrial animal operations, where an “animal operation” is defined as any operation that produces land animals for food, irrespective of size or methods of production. Exposure to these operations may be estimated using any relevant metric including physical distance to an operation, animal density, or levels of an indicator contaminant (e.g., endotoxins). We aim to study all relevant health outcomes, which includes a wide range of physician-diagnosed or self-reported outcomes, ranging from quality-of-life measures to sub-clinical measures of disease (e.g., biomarkers).” (Lines 101-111)**  4. Judging the feasibility of the planned research is challenging, but as a very open-ended mapping exercise in its own right it could be a lot of data, and as a systematic review it is almost certainly not feasible to evaluate certainty of the evidence for all of the exposure-outcome relationships that are anticipated. No information has been provided about the number of results from the search strategy, likely number of included studies from a screening process, or other data that allows feasibility to be evaluated. I strongly recommend the authors gather some data for this to use in their planning process.  **We agree that judging the feasibility of the planned research is challenging given the limited information we had previously provided in our protocol. We have added the number of results from the search strategy and anticipated the number of studies to undergo full text screening:**  **“Our search strategy was developed and modified through an iterative piloting process, and various investigators (RS, EC, BK, KN) collaborated with our information specialist (LR) during the entire search’s development. In addition, we used the final list of studies included by O’Connor et al. (2017) as a list of benchmark studies to be returned by our search strategy. As of May 10th, 2024, the search strategy returns 25,935 articles, prior to deduplication. A pilot title/abstract screening of 200 of the returned studies resulted in 3 advancing to full text screening (1.5%). Therefore, we anticipate that approximately 375 articles will undergo full text screening in the final review.” (Lines 155-162).** |

| **Domain** | D2. Planned selection methods will not exclude relevant evidence |
| --- | --- |
| **Compliance** | Important issues identified that should be addressed prior to peer-review |
| **Specific Issues** | R Appropriateness of eligibility criteria in context of research objectives  R Potential ambiguity or vagueness of the eligibility criteria  N Potential for screening process to exclude relevant evidence  X Other issues (indicated below) |
| **Comments** | 1. Two eligibility criteria are ambiguous: what counts as an animal operation, and what counts as “living close to” animal operations. These should be clarified.  **We have chosen to utilize the term “animal feeding operations” to better describe the types of facilities we are interested in. We have defined “animal feeding operation” in our dictionary (Section 4.1) as follows:**  **“Animal feeding operation will be defined as any operation that produces land animals for food, irrespective of size or methods of production. Our use of the term should not be confused with the regulatory designation “AFO” as defined by the US Environmental Protection Agency.” (Lines 402-404)**  **We agree that “living close to animal operations” is an ambiguous way to define our exposure criteria. We have chosen to change our inclusion criteria to include any community-based exposures to animal operations to reduce ambiguity:**  **“Community exposure (e.g., residential, school) to an animal feeding operation estimated/assessed using any relevant metric, including distance to the nearest operation, farm and/or animal density, perceived odor, or levels of an indicator contaminant (e.g., endotoxins)” (Section 4.6.1., Table 1)**  2. Otherwise, the authors aim to include everything published in journals around this topic, so long as it involves an exposure and a health outcome. The risk of excluding relevant evidence is therefore minimal, but it might come at the expense of a feasible or suitably focused piece of research.  **We plan to include all studies published in journals as long as they meet our PECO criteria. We agree that the risk of excluding relevant evidence is minimal.** |

| **Domain** | D3. Search strategy is sufficiently comprehensive |
| --- | --- |
| **Compliance** | Important issues identified that should be addressed prior to peer-review |
| **Specific Issues** | R Search sensitivity, with adequate conceptual and database coverage  N Reproducibility of search strategy  R Validation of search strategy  X Other issues (indicated below) |
| **Comments** | 1. For evaluation of the strategy, it would be useful to present it in terms of core search concepts and how these are executed, then how these are combined in the overall approach. This should be supported by explanation of the reason for the structure of the search and the choice of endpoints (for example I have questions about why antibiotic resistance is a concept in the search, and why if there is an epidemiology concept then some but not all diseases also need to be a search concept?).  **We have revised our manuscript to better describe the structure of the search strategy and our search strategy development process:**  **"Our search strategy (4.6.2. Table 2) builds upon a previous systematic review’s search (O’Connor et al., 2017), with a few major modifications. We added two additional terms to O’Connor et al.’s (2017) search, one composed of relevant human health outcomes, and one composed of epidemiology study design terms, to capture a more holistic set of outcomes and a broader set of health-relevant studies. Therefore, our search comprises four main concepts: animal production operations (search lines 1-8), community health terms (search lines 10-13), specific human health outcomes (search lines 16-33) and epidemiologic study design (search lines 35-37). The epidemiologic study concept is adapted from searches available on the InterTASC Information Specialists’ Sub-Group (ISSG) Search Filter Resource (ISSG, 2024), which provides researchers with study design-specific search filters.**  **Our search strategy was developed and modified through an iterative piloting process, and various investigators (RS, EC, BK, KN) collaborated with our information specialist (LR) during the entire search’s development. In addition, we used the final list of studies included by O’Connor et al. (2017) as a list of benchmark studies to be returned by our search strategy.”** **(Lines 144-162)**  2. The search strategy includes an uneven mix of wildcards and pluralisations.  **We have revised our search strategy to remove unnecessary terms and to be more consistent in our pluralization. In our search strategy, we chose to not truncate words three letters or shorter to avoid adding an unnecessary number of irrelevant studies. For example, for the term “cow”, we had “cow” and “cows”, whereas for words four letters or longer, we truncated (e.g., “lamb\*”). Our updated search strategy can be found in Section 4.6.2.**  3. If search strategies have been defined for several databases, it can be helpful to present all of them.  **We recently made significant updates to our search strategy including adding additional health outcomes and reducing redundancies and pluralizations (see Comment #2 above). Our search strategy for Ovid Medline can be found in Section 4.6.2. Our informationist is currently defining the searches for the other databases we plan to search, but we do not have them ready at this time. We plan to include them in our revision after peer-review.**  4. If arable farming that uses manure as fertiliser is relevant in terms of topic, then I am not sure the search strategy (with its focus on industrial and intensive farming) will necessarily find this evidence.  **We agree with the editor’s statement that manure application is out of our scope given our search strategy and research question. Consequently, we have decided to exclude studies focusing on where manure is spread and have removed all language referring to manure spreading. We have also refined our exclusion criteria for exposure as follows:**  **“Studies without an exposure to an animal operation; Indirect exposure via a relative who works on a farm” (Section 4.6.1., Table 1)** |

| **Domain** | D4. Data abstraction and coding methods are fit for purpose |
| --- | --- |
| **Compliance** | Important issues identified that should be addressed prior to peer-review |
| **Specific Issues** | R Code book or abstraction sheets show coding strategy appropriate to objectives  N Quality controls on data abstraction and coding decisions (e.g. duplicate)  R Transparency and reproducibility of coding or abstraction strategy  X Other issues (indicated below) |
| **Comments** | 1. I recommend presenting the planned abstracted data in the form of a draft table of the key characteristics of included studies, so the reviewers can evaluate whether the data being collected is sufficient for the purposes of the systematic review. Presenting this information in narrative form is difficult to evaluate, and unclear if it is comprehensively accounted for.  **We thank the editor for this suggestion and agree that our “Data items” narrative was difficult to evaluate. We have opted to include our data items alongside our sample codebook in Section 4.6.3. We have noted this in the manuscript:**  **“The data items collected for each study are listed in our supplementary materials (4.6.3).” (Line 215)**  2. The authors present examples of what may be coded, rather than a complete code book. For peer-review, we would need to see the complete code book in order to provide comprehensive feedback on the planned methods. Specifically for outcomes, the authors may wish to use a standardised outcome vocabulary such as WHO ICD-10.  **We have included a draft codebook housed on Open Science Framework that is linked in Section 4.6.3. At this time, we feel unable to provide a final codebook because we have not yet seen our data and expect our codebook development to be an iterative process:**  **“We plan to use a coding process to analyze our data after extraction. We have created a sample codebook (Section 4.6.4) based on our training dataset. Once all data has been extracted, we will begin coding the data using an iterative process. During this process, new codes will be created as necessary and previously coded data will be revisited as the codebook evolves.” (Lines 247-250)**  **We opted to not use ICD-10 codes for our health outcome coding, as we feel these codes are too specific for the data we have seen in our pilot. We may use ICD-10 codes in our final coding process, depending on the specificity of the outcomes reported by our final list of studies.**  3. I would recommend piloting data abstraction on a subset of eligible studies to check that the planned approach will work as intended, and allow the peer-reviewers to provide feedback on this part of the methodology as well. The data collection forms could at least be provided for peer-review.  **We thank the editor for this suggestion and have conducted a pilot of our data extraction process. We have included the data collection forms we plan to use in Table 3, in Section 4.6.3. We look forward to the peer reviewers’ feedback on our data extraction process and form.** |

| **Domain** | D5. Critical appraisal of individual studies is fit for purpose |
| --- | --- |
| **Compliance** | Important issues identified that may be addressed after peer-review |
| **Specific Issues** | N Suitability of appraisal instrument according to FEAT\* criteria  R Quality controls on appraisal (e.g. duplicate appraisal, conflict resolution)  X Other issue (indicated below)  \* Focus, Extent, Application, Transparency (Frampton et al. 2022) |
| **Comments** | 1. Information about how many investigators will assess risk of bias, training, agreement checks, piloting of method etc. seems to be missing from the protocol.  **We have added an explanation of our process for resolving disagreement that we plan to use for both our title/abstract and full text screening rounds:**  **“At both stages of review, disputes between two reviewers will be resolved a senior investigator (RS, DL, ATL, KN). The first 10% of screened studies will be reviewed for quality control by a third reviewer as well. All authors that will screen studies will take part in a training/pilot screening process. The authors will all screen the same set of returned studies (approx. 500 studies) and any disagreements among the screeners will be discussed over video conference until a consensus is reached.” (Lines 188-193)**  **We have added information about our training process for data extraction:**  **“All authors that will participate in data extraction will take part in a training process during which each of the investigators will independently extract data from a pre-selected set of studies. Each data item extracted by each extractor will be compared, and if disagreements arise, it will be discussed by the entire group of extractors. In the event of duplicate publications, or multiple reports of a primary study, we will collate all available data and use the most complete dataset including the highest quality estimate of the exposure-outcome relationship taken from all identified publications.” (Line 205-211).**  **We have also added information on the number of risk of bias assessors:**  **“Each study will undergo RoB assessment by two co-investigators (RS, JL, DL, ATL, KN).” (Lines 240-241)**  2. There may be a question about the feasibility of conducting a full risk of bias assessment for all studies, if the goal of the exercise is to map the evidence. It may be more aligned with the objectives to survey the evidence for indicators of rigour or study design characteristics that are informative of the quality of the evidence, but not necessarily assess the internal validity of the evidence.  **Our research objective is to conduct a systematic review and thus we are planning to conduct a full risk of bias assessment for all studies. We believe this is feasible as we will have likely have around 375 full texts to screen, and anticipate the final number of included studies to be relatively small:**  **“As of May 10th, 2024, the search strategy returns 25,935 articles, prior to deduplication. A pilot title/abstract screening of 200 of the returned studies resulted in 3 advancing to full text screening (1.5%). Therefore, we anticipate that approximately 375 articles will undergo full text screening in the final review.” (Lines 159-162)** |

| **Domain** | D6. Evidence synthesis methods |
| --- | --- |
| **Compliance** | Important issues identified that should be addressed prior to peer-review |
| **Specific Issues** | R Sufficiently detailed analysis pipeline for establishing target relationships  R Appropriately developed secondary or exploratory analyses  R Validity of analysis pipeline, e.g. statistical or qualitative methods, subgroups, etc.  X Other issue (indicated below) |
| **Comments** | 1. The description of the approach to evidence synthesis only lays out options and considerations that would inform decisions, rather than a plan for conducting a series of meta-analyses. This is fully exploratory, which is fine in principle, but issues around e.g. multiple testing should be accounted for.  **We plan to use a codebook as part of our data synthesis to help us characterize the data we collect:**  **“We plan to use a coding process to analyze our data after extraction. We have created a sample codebook (Section 4.6.4) based on our training dataset. Once all data has been extracted, we will begin coding the data using an iterative process. During this process, new codes will be created as necessary and previously coded data will be revisited as the codebook evolves.” (Lines 247-250)**  **We have not explicitly outlined a plan for conducting meta-analyses as we do not anticipate a traditional meta-analysis being possible due to the heterogeneity of studies:**  **“Based on previous reviews (O’Connor et al., 2010, 2017; Son et al., 2024), we anticipate that many of the studies identified in our review will have heterogeneity in their design, such as exposure assessment, outcome assessment, and statistical methods. As a result, we do not anticipate a traditional meta-analysis being possible (Casey et al., 2015; Son et al., 2024). We will not exclude studies solely based on compatibility with other studies for meta-analysis, but we plan to combine compatible studies, when possible, to generate summary estimates that could provide insight into quantitative relationships between community exposure to animal operations and adverse human health outcomes.” (Lines 252-258)**  2. There is also the question of the value of a protocol that does not in fact present a plan for analysis. At the moment, the protocol seems mainly to be functioning as an announcement of intent to conduct an analysis, rather than presenting the plan for what the analysis will be. This is fine if it is the goal, but this minimum information is not sufficient for evaluating whether the planned methods are appropriate to delivering the research goal.  **We have revised our manuscript to present a plan for analysis:**  **“We will synthesize data into summary measures when individual studies are sufficiently similar, allowing for meaningful comparisons and synthesis of findings. Quantitative synthesis will be contingent upon whether study designs are compatible (e.g., all cross-sectional design), exposures and outcome measures are comparable, outcome measures are reported on similar scales or can be converted to the same scale, and the included studies are methodologically sound. Potential summary statistics may include prevalence Odds Ratios (OR), regression coefficients (*β*s, or mean differences), or prevalence ratios. Heterogeneity will be explored using I2 statistic, a measure that quantifies the degree of variability among effect sizes from individual studies. It represents the proportion of total variation across studies that is due to heterogeneity rather than chance. The I2 statistic is interpreted as indicating low heterogeneity (0-40%), moderate heterogeneity (30-60%), substantial heterogeneity (50-90%), or considerable heterogeneity (75-100%) (Higgins et al., 2023). Although an assessment of the I2 can be informative, it is also important to contextualize this metric with other factors such as study quality, sample size, and methodological diversity across studies when interpreting the meta-analysis results.**  **We may also perform sensitivity analyses by examining the effects of excluding studies with heterogeneous results as well as performing subgroup analyses by excluding individual or subsets of studies with characteristics that might be influential. For example, we may conduct a sub-analysis on school-based exposure studies as compared to residence-based exposure studies. If enough studies are available, a more formal approach to perform a subgroup analysis, clustering studies by specific characteristics to determine the impact on statistical heterogeneity, will be conducted.**  **For studies that are not amenable to quantitative synthesis, we will use the Synthesis without Meta-analysis (SwiM) reporting guideline, which was developed for use in systematic reviews in which meta-analyses of effect estimates may not be possible or appropriate for at least some outcomes (Campbell et al., 2020). Although this guideline was developed for the presentation of intervention studies rather than observational studies, many of the reporting items outlined are still applicable to observational study presentation, including the need to explain criteria used to prioritize results for summary and synthesis, explain and provide a rationale for groups used in synthesis, describe methods used to assess certainty of the synthesis findings, describe data presentation methods, and to report on the limitations of the synthesis (Campbell et al., 2020).” (Lines 260-293)**  3. Overall, adding in the SWIM analyses as well, I wonder about the feasibility of the approach being described as there is a completely open-ended, almost unlimited choice of exposure-outcome pairs that could be analysed. The authors are going to have to make choices about what to analyse, so should ideally anticipate these in the protocol rather than leaving things so open. Are there no primary hypotheses they are wanting to test, or is it really a completely exploratory exercise they want to conduct of all possible exposure-outcome combinations?  **Thank you for this comment. We have introduced three hypotheses to our review that will help limit the large number of exposure-outcome combinations:**  **“We plan to test the following three hypotheses in our systematic review:**   1. **People with community-based exposures to industrial animal operations are more likely to experience adverse respiratory health outcomes compared to individuals living further from industrial animal operations.** 2. **People with community-based exposures to industrial animal operations are more likely to experience adverse gastrointestinal outcomes compared to individuals living further from industrial animal operations.** 3. **People with community-based exposures to industrial animal operations are more likely to be colonized or infected with pathogens (e.g., *E. coli*, *Salmonella)* compared to individuals living further from industrial animal operations.” (Lines 113-122)** |

| **Domain** | D7. Certainty assessment methods |
| --- | --- |
| **Compliance** | Moderate to minor issues identified that may be addressed after peer-review |
| **Specific Issues** | N Appropriateness of certainty assessment framework according to FEAT criteria  N Suitable method for assessing each domain of the certainty framework  X Other issue (indicated below) |
| **Comments** | 1. My comments about the number of analyses and appropriateness of a systematic review methodology for open-ended exploratory work apply here as well, as there is the potential for certainty assessment of an unspecified and potentially very large number of exposure-outcome relationships. However, the proposed methodology itself seems sufficiently described for peer-review and there are no obvious issues with the validity of the approach. I would suggest the authors include a planned summary of evidence table just to round out the detail in reporting of anticipated approach.  **In line with other comments, we have added a sample data extraction form with our planned data items in Section 4.6.3.** |

# Notes and guidance for submitting authors

This is an editorial triage report for systematic review protocols. It has been derived from the CREST\_Triage tool for editorial appraisal of systematic reviews (Whaley and Isalski, 2019). CREST\_Triage was designed to help editors make consistent, transparent decisions about whether to advance a SR submission to peer review. For EBT, CREST\_Triage has been adapted for checking compliance with EBT’s open data standards.

**Citations**

Whaley, P. and Isalski, M. (2019) *CREST\_Triage* [Browser-based]. Available at: <https://crest-tools.site/>.

Whaley, P. and Roth, N. (2022) ‘CREST\_triage: Appraisal tools for systematic reviews and systematic evidence maps’. Open Science Framework. Available at: https://doi.org/10.17605/OSF.IO/U4J5M.